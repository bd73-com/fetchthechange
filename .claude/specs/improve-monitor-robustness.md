# Feature: Improve Monitor Robustness
> Specification generated by /interview on 2026-02-18
> This is a planning document. No implementation code has been written.

## Implementation Instructions
This specification is context for the implementing agent. Read and internalize it fully before writing any code.

**IMPORTANT -- Do NOT:**
- Add comments referencing this spec (no `// See spec: ...`, no `// REQ-001`, no `// Don't #3`)
- Structure code around spec sections -- structure it around clean domain logic
- Embed spec traceability IDs in code, comments, variable names, or test names
- Add comments explaining "why" when the code is self-documenting

**DO:**
- Write clean, idiomatic code that follows the reference implementation patterns
- Let the constraints from this spec guide your decisions silently -- they should be invisible in the final code
- Name things after domain concepts, not spec concepts
- Write tests that verify behavior, named after what they verify (not after spec requirement IDs)

## Overview
The monitor feature periodically checks web pages for changes using a two-stage scraper (static HTML fetch + Browserless headless browser fallback). Currently, monitors that encounter persistent failures keep retrying identically forever, wasting expensive Browserless quota and producing noise. This feature adds consecutive-failure tracking, auto-pause with tier-differentiated thresholds, scheduler jitter, structured per-check metrics, and user-facing pause reason display.

## Scope
### In Scope
- Consecutive failure counter on monitors
- Auto-pause after N failures (Free=3, Pro=5, Power=10)
- Auto-pause notification email
- Manual re-enable via UI resets failure counter
- Random jitter (0-30s) for concurrent scheduled checks
- Structured per-check metrics table
- Admin metrics API endpoint
- Frontend display of pause reason

### Out of Scope
- Exponential backoff for check frequency
- Automatic re-enable / self-healing
- User-configurable pause thresholds
- Rotating User-Agents or request header variation

### Deferred
- Dashboard visualization of metrics data
- Per-domain success rate analytics in the admin UI

## Reference Implementation
- Reference: `server/services/browserlessTracker.ts` for tier-based caps and usage tracking
- Reference: `server/services/email.ts` for email notification patterns
- Reference: `server/routes.ts` admin endpoints for auth pattern (power tier + APP_OWNER_ID)

## Codebase Context
- Architecture: Express + React SPA, monorepo with shared/ for types
- ORM: Drizzle with PostgreSQL
- API framework: Express with Zod validation
- Validation: Zod schemas via drizzle-zod
- Error handling: ErrorLogger service with DB persistence and redaction

## Requirements
- Track consecutive failures per monitor (`consecutiveFailures` integer, default 0)
- Reset counter to 0 on any successful check
- Auto-pause monitor when failures reach tier threshold
- Store human-readable `pauseReason` on auto-paused monitors
- Send email notification when a monitor is auto-paused
- Reset `consecutiveFailures` and `pauseReason` when user re-enables
- Do NOT penalize monitor failure count for Browserless infrastructure errors
- Stagger concurrent monitor checks with random 0-30s jitter
- Record structured metrics for each check stage (static, static_retry, browserless)
- Expose admin endpoint for failure-rate-by-domain, duration-by-stage, browserless ratio, auto-pause events

## Prohibitions (Don'ts)
- NEVER retry Browserless more than once per check -- quota is expensive
- NEVER auto-unpause a paused monitor without user action
- NEVER fire all due monitors simultaneously -- stagger with jitter
- NEVER change retry behavior based on tier -- only pause threshold varies
- NEVER lose the last-known-good value when a check fails
- NEVER penalize monitor failure count when Browserless itself is unavailable

## Decision Tree
```
Monitor check triggered
+-- Static fetch
|   +-- Success -> extract value -> done (reset failure count)
|   +-- Blocked -> try Browserless if available
|   |   +-- Success -> done (reset failure count)
|   |   +-- Infra error -> log, DON'T increment failures
|   |   +-- Page error -> increment failures
|   +-- Selector missing -> increment failures
|   +-- Network error -> retry once (2s)
|       +-- Still fails -> increment failures
|       +-- Succeeds -> done (reset failure count)
|
+-- After incrementing failure count:
    +-- >= threshold -> auto-pause + email user
    +-- < threshold -> continue normally
```

## Domain Rules & Exceptions
| Rule | Applies When | Exception | Who Can Override |
|------|-------------|-----------|-----------------|
| Auto-pause at threshold | consecutiveFailures >= PAUSE_THRESHOLDS[tier] | Browserless infra errors don't count | User (manual re-enable) |
| Jitter 0-30s | Multiple monitors due in same minute | N/A | N/A |
| Failure count reset | Check succeeds (status=ok) | N/A | User (re-enable also resets) |

## Escalation & Guardrails
- **Fail if**: Browserless infra unavailable -- fail fast, try next cycle
- **Queue for review if**: N/A
- **Retry/degrade if**: Static fetch fails -- one retry after 2s delay
- **Alert if**: Monitor auto-paused -- email to user

## Data Model
New columns on `monitors` table:
- `consecutive_failures` integer NOT NULL DEFAULT 0
- `pause_reason` text NULL

New table `monitor_metrics`:
- `id` serial PK
- `monitor_id` integer FK -> monitors
- `checked_at` timestamp DEFAULT now()
- `stage` text ('static' | 'static_retry' | 'browserless')
- `duration_ms` integer
- `status` text ('ok' | 'blocked' | 'selector_missing' | 'error')
- `selector_count` integer
- `blocked` boolean DEFAULT false
- `block_reason` text NULL

New constant in `shared/models/auth.ts`:
- `PAUSE_THRESHOLDS = { free: 3, pro: 5, power: 10 }`

## API Contract
### GET /api/admin/monitor-metrics
- Auth: Power tier + APP_OWNER_ID
- Success: 200 with `{ failuresByDomain, avgDurationByStage, browserlessStats, autoPauseEvents }`
- Error: 403 if not admin/owner

### PATCH /api/monitors/:id (existing, modified)
- When `active: true` and monitor was inactive: also resets `consecutiveFailures` to 0 and clears `pauseReason`

## Frontend Changes
- `MonitorCard.tsx`: amber warning banner when `pauseReason` is non-null
- `MonitorDetails.tsx`: amber alert box with pause reason and re-enable guidance

## Acceptance Criteria
### Happy Path
- [ ] Given a monitor check succeeds, consecutiveFailures resets to 0
- [ ] Given 3 monitors are due simultaneously, each starts with random 0-30s jitter

### Negative / Prohibition Tests
- [ ] Given Browserless extraction fails, it is NOT retried within the same check
- [ ] Given a monitor is auto-paused, it does NOT automatically resume
- [ ] Given failures occur, currentValue still holds the last successful value

### Edge Cases
- [ ] Given a Free-tier monitor fails 3 times, it is auto-paused with email sent
- [ ] Given a Pro-tier monitor fails 4 times, it is NOT yet paused (threshold=5)
- [ ] Given selector_missing failures, they count toward auto-pause threshold
- [ ] Given user re-enables a paused monitor, consecutiveFailures resets to 0

### Integration / Resilience
- [ ] Given Browserless is unreachable, monitor's failure count is NOT incremented
- [ ] Given a network error on static fetch, one retry is attempted after 2s

## Files to Create / Modify
- Modify: `shared/models/auth.ts` -- add PAUSE_THRESHOLDS constant
- Modify: `shared/schema.ts` -- add consecutiveFailures, pauseReason columns; add monitorMetrics table
- Modify: `server/services/scraper.ts` -- failure tracking, auto-pause, metrics recording, infra error isolation
- Modify: `server/services/scheduler.ts` -- random jitter for concurrent checks
- Modify: `server/services/email.ts` -- add sendAutoPauseEmail function
- Modify: `server/routes.ts` -- reset on re-enable, metrics admin endpoint
- Modify: `client/src/components/MonitorCard.tsx` -- pause reason warning banner
- Modify: `client/src/pages/MonitorDetails.tsx` -- pause reason alert box

## Observability
- Log: check stage results at info level (already via console.log)
- Log: auto-pause events at info level
- Metrics: per-check stage timing and status in monitor_metrics table
- Metrics: admin endpoint exposes failure-by-domain, duration-by-stage, browserless ratio
- Never log: user emails, tokens, API keys (existing redaction handles this)

## Key Decisions Made
| Decision | Options Considered | Chosen | Rationale |
|----------|-------------------|--------|-----------|
| Failure handling | Backoff / Auto-pause / Both | Auto-pause after N failures | Simplest, conserves quota effectively |
| Pause threshold | Same for all / Tier-differentiated | Tier-differentiated (3/5/10) | Higher-paying users tolerate more flakiness |
| Notification | UI only / Email on pause / Warning + pause email | Email on auto-pause | One email is sufficient, avoids spam |
| Browserless infra failure | Penalize / Don't penalize | Don't penalize | Infrastructure issues aren't the monitor's fault |
| Staggering | Random jitter / Even distribution | Random jitter 0-30s | Simple to implement, effective enough |
| Re-enable | Auto + manual / Manual only / Manual + immediate check | Manual re-enable via UI | KISS, avoids auto-unpause prohibition |

## Open Questions
None -- all decisions resolved during interview.
